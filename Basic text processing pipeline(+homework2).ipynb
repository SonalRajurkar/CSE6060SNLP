{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Become', 'an', 'expert', 'in', 'NLP']\n",
      "['The', 'only', 'true', 'wisdom', 'is', 'in', 'knowin', \"'\", 'you', 'know', 'nothing', '.']\n",
      "['Beware', 'the', 'barrenness', 'of', 'a', 'busy', 'life', '.']\n",
      "['I', 'decided', 'that', 'it', 'was', 'not', 'wisdom', 'that', 'enabled', 'poets', 'to', 'write', 'their', 'poetry', ',', 'but', 'a', 'kind', 'of', 'ins', '.']\n",
      "['or', 'inspiration', ',', 'such', 'as', 'you', 'find', 'in', 'seers', 'and', 'prophets', 'who', 'deliver', 'all', 'their', 'sublime', 'messages', 'without', 'knowing', 'in', 'the', 'least', 'what', 'they', 'mean', '.']\n",
      "['Be', 'as', 'you', 'wish', 'to', 'seem', '.']\n",
      "['Wonder', 'is', 'the', 'beginning', 'of', 'wisdom', '.']\n",
      "['Be', 'kind', ',', 'for', 'everyone', 'you', 'meet', 'is', 'fighting', 'a', 'hard', 'battle', '.']\n",
      "['Our', 'prayers', 'should', 'be', 'for', 'blessings', 'in', 'general', ',', 'for', 'God', 'knows', 'best', 'what', 'is', 'good', 'for', 'us', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sent = \"Become an expert in NLP\"\n",
    "words = nltk.word_tokenize(sent)   #Converting the sentence into tokens \n",
    "print(words)\n",
    "\n",
    "texts = [\"\"\"The only true wisdom is in knowin' you know nothing.\n",
    "Beware the barrenness of a busy life.\n",
    "I decided that it was not wisdom that enabled poets to write their poetry,\n",
    "but a kind of ins. or inspiration, such as you find in seers and prophets who deliver all their sublime messages without knowing in the least what they mean. Be as you wish to seem. Wonder is the beginning of wisdom. Be kind, for everyone you meet is fighting a hard battle.  Our prayers should be for blessings in general, for God knows best what is good for us.\"\"\"]\n",
    "\n",
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        print(words)                #Displays every word in a line alongwith the punctuation (\",\",\".\") \n",
    "                                     #As soon as the full stop occurs, it treats the next sentence as the new line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Become', 'an', 'expert', 'in', 'NLP']\n",
      "[('The', 'DT'), ('only', 'JJ'), ('true', 'JJ'), ('wisdom', 'NN'), ('is', 'VBZ'), ('in', 'IN'), ('knowin', 'NN'), (\"'\", \"''\"), ('you', 'PRP'), ('know', 'VBP'), ('nothing', 'NN'), ('.', '.')]\n",
      "[('Beware', 'NNP'), ('the', 'DT'), ('barrenness', 'NN'), ('of', 'IN'), ('a', 'DT'), ('busy', 'JJ'), ('life', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('decided', 'VBD'), ('that', 'IN'), ('it', 'PRP'), ('was', 'VBD'), ('not', 'RB'), ('wisdom', 'JJ'), ('that', 'IN'), ('enabled', 'VBD'), ('poets', 'NNS'), ('to', 'TO'), ('write', 'VB'), ('their', 'PRP$'), ('poetry', 'NN'), (',', ','), ('but', 'CC'), ('a', 'DT'), ('kind', 'NN'), ('of', 'IN'), ('ins', 'NNS'), ('.', '.')]\n",
      "[('or', 'CC'), ('inspiration', 'NN'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('you', 'PRP'), ('find', 'VBP'), ('in', 'IN'), ('seers', 'NNS'), ('and', 'CC'), ('prophets', 'NNS'), ('who', 'WP'), ('deliver', 'VBP'), ('all', 'DT'), ('their', 'PRP$'), ('sublime', 'NN'), ('messages', 'NNS'), ('without', 'IN'), ('knowing', 'VBG'), ('in', 'IN'), ('the', 'DT'), ('least', 'JJS'), ('what', 'WP'), ('they', 'PRP'), ('mean', 'VBP'), ('.', '.')]\n",
      "[('Be', 'VB'), ('as', 'IN'), ('you', 'PRP'), ('wish', 'VBP'), ('to', 'TO'), ('seem', 'VB'), ('.', '.')]\n",
      "[('Wonder', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('beginning', 'NN'), ('of', 'IN'), ('wisdom', 'NN'), ('.', '.')]\n",
      "[('Be', 'NNP'), ('kind', 'NN'), (',', ','), ('for', 'IN'), ('everyone', 'NN'), ('you', 'PRP'), ('meet', 'VBP'), ('is', 'VBZ'), ('fighting', 'VBG'), ('a', 'DT'), ('hard', 'JJ'), ('battle', 'NN'), ('.', '.')]\n",
      "[('Our', 'PRP$'), ('prayers', 'NNS'), ('should', 'MD'), ('be', 'VB'), ('for', 'IN'), ('blessings', 'NNS'), ('in', 'IN'), ('general', 'JJ'), (',', ','), ('for', 'IN'), ('God', 'NNP'), ('knows', 'VBZ'), ('best', 'JJS'), ('what', 'WP'), ('is', 'VBZ'), ('good', 'JJ'), ('for', 'IN'), ('us', 'PRP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "sent = \"Become an expert in NLP\"\n",
    "words = nltk.word_tokenize(sent)   #Converting the sentence into tokens \n",
    "print(words)\n",
    "\n",
    "texts = [\"\"\"The only true wisdom is in knowin' you know nothing.\n",
    "Beware the barrenness of a busy life.\n",
    "I decided that it was not wisdom that enabled poets to write their poetry,\n",
    "but a kind of ins. or inspiration, such as you find in seers and prophets who deliver all their sublime messages without knowing in the least what they mean. Be as you wish to seem. Wonder is the beginning of wisdom. Be kind, for everyone you meet is fighting a hard battle.  Our prayers should be for blessings in general, for God knows best what is good for us.\"\"\"]\n",
    "\n",
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged = nltk.pos_tag(words)  #Special label assigned to each token which makes seraching efficient\n",
    "        print(tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176967"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r\\n\\r\\nThis eBook is for the '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=word_tokenize(raw) #Tokenizing the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257727"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Crime',\n",
       " 'and',\n",
       " 'Punishment',\n",
       " ',',\n",
       " 'by',\n",
       " 'Fyodor',\n",
       " 'Dostoevsky',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:30] #First 30 words/tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tagged=nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\ufeffThe', 'NN'),\n",
       " ('Project', 'NNP'),\n",
       " ('Gutenberg', 'NNP'),\n",
       " ('EBook', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Crime', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('Punishment', 'NNP'),\n",
       " (',', ','),\n",
       " ('by', 'IN'),\n",
       " ('Fyodor', 'NNP'),\n",
       " ('Dostoevsky', 'NNP'),\n",
       " ('This', 'DT'),\n",
       " ('eBook', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('use', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('anyone', 'NN')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿the project gutenberg ebook of crime and punish , by fyodor dostoevski thi ebook is for the use of anyon anywher at no cost and with almost no restrict whatsoev . you may copi it , give it away or re-us it under the term of the project gutenberg licens includ with thi ebook or onlin at www.gutenberg.org titl : crime and punish author : fyodor dostoevski releas date : march 28 , 2006 [ ebook # 2554 ] last updat : octob 27 , 2016 languag : english charact set encod : utf-8 *** start OF thi project gutenberg ebook crime and punish *** produc by john bicker ; and dagni crime and punish By fyodor dostoevski translat By constanc garnett translat ’ S prefac A few word about dostoevski himself may help the english reader to understand hi work . dostoevski wa the son of a doctor . hi parent were veri hard-work and deepli religi peopl , but so poor that they live with their five children in onli two room . the father and mother spent their even in read aloud to their children , gener from book \n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "def stemmedSentence(raw):\n",
    "    stemmed_sentence=[]\n",
    "    for word in tokens:\n",
    "        stemmed_sentence.append(porter.stem(word))\n",
    "        stemmed_sentence.append(\" \")\n",
    "    return \"\".join(stemmed_sentence)\n",
    "\n",
    "x=stemmedSentence(raw)\n",
    "print(x[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
